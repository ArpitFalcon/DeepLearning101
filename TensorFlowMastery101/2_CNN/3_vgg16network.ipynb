{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_vgg16network",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G81Xd8qpCt7M",
        "colab_type": "text"
      },
      "source": [
        "# VGG 16 Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRGzLDwVCuCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68eBK_sYCv-b",
        "colab_type": "text"
      },
      "source": [
        "### Define a VGG16 Network\n",
        "Note - The weights used here is pretrained and are stored [here.](https://www.kaggle.com/keras/vgg16?select=vgg16_weights_tf_dim_ordering_tf_kernels.h5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqlS4kP3CxGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VGG_16(weights_path=None):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.ZeroPadding2D((1, 1), input_shape=(224, 224, 3)))\n",
        "    model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(256, (3, 3), activation='relu'))\n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(256, (3, 3), activation='relu'))\n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(256, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(layers.ZeroPadding2D((1,1)))\n",
        "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(layers.Flatten())\n",
        "    \n",
        "    #top layer of the VGG net\n",
        "    model.add(layers.Dense(4096, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(4096, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(1000, activation='softmax'))\n",
        "    \n",
        "    if weights_path:\n",
        "        model.load_weights(weights_path)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWYmHqHxC_m6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c76b8710-9166-4e23-9ce6-1ef762d0eb23"
      },
      "source": [
        "# Downloading the dataset from kaggle\n",
        "# %cd drive\n",
        "# %cd 'My Drive'\n",
        "# %cd Kaggle\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/Kaggle\"\n",
        "\n",
        "!kaggle datasets download -d keras/vgg16"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vgg16.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9U53yLTKOQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using the predefined weights\n",
        "import cv2\n",
        "im = cv2.resize(cv2.imread('/content/drive/My Drive/projects/steam-locomotive.jpg'), (224,224)).astype(np.float32)\n",
        "# im = im.transpose((2, 0, 1))\n",
        "im = np.expand_dims(im, axis=0)\n",
        "\n",
        "# Test the pretrained model\n",
        "model = VGG_16('/content/drive/My Drive/kaggle/vgg_16_weights_tf_dim_ordering_tf_kernerls.h5')\n",
        "model.summary()\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
        "out = model.predict(im)\n",
        "print(np.argmax(out))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN9kVGmeFGZk",
        "colab_type": "text"
      },
      "source": [
        "# Utilizing tf.keras built-in VGG16 Net module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_mDAzZZEXp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a346afde-821a-4133-a213-692942c45c4c"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# prebuild model with pre-trained weights on imagenet\n",
        "model = VGG16(weights='imagenet', include_top=True)\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
        "\n",
        "# resize into VGG16 trained images' format\n",
        "image = cv2.imread('/content/drive/My Drive/projects/steam-locomotive.jpg', 1)\n",
        "im = cv2.resize(image, (224, 224)).astype(np.float32)\n",
        "im = np.expand_dims(im, axis=0)\n",
        "\n",
        "# predict\n",
        "out = model.predict(im)\n",
        "index = np.argmax(out)\n",
        "print(index)\n",
        "\n",
        "plt.plot(out.ravel())\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "820\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apSKB33BFvVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}